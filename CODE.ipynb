{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from PIL import Image\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")\n",
    "base_path=\"./images/\"\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = 20000\n",
    "df = df.loc[df[\"id\"].str.startswith('00', na=False), :]\n",
    "num_classes =len(df[\"landmark_id\"].unique())\n",
    "num_data=len(df)\n",
    "print (num_classes)\n",
    "print (num_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(df[\"landmark_id\"].value_counts())\n",
    "data.reset_index(inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns= ['landmark_id','count']\n",
    "data['count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(data['count'], 100, range=(0,994), label='test' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['count'].between(0,15).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "lencoder = LabelEncoder()\n",
    "lencoder.fit(df[\"landmark_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_label(lbl):\n",
    "    return lencoder.tranform(lbl)\n",
    "def decode_label(lbl):\n",
    "    return lencoder.inverse_transform(lbl)\n",
    "def get_image_from_number(num):\n",
    "    fname, label= df.loc[num, :]\n",
    "    fname = fname + '.jpg'\n",
    "    f1 = fname[0]\n",
    "    path = os.path.join(f1, fname)\n",
    "    im=cv2.imread(os.path.join(base_path, path))\n",
    "    return im, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\"4 sample images are\")\n",
    "fig = plt.figure(figsize=(16,16))\n",
    "for i in range (1,5):\n",
    "    ri = random.choices(os.listdir(base_path), k=3)\n",
    "    folder = base_path + '/' + ri[0] \n",
    "    random_img =random.choice(os.listdir(folder))\n",
    "    img = np.array(Image.open(folder + '/' + random_img))\n",
    "    fig.add_subplot(1,4,i)\n",
    "    plt.imshow(img)\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.layers import *\n",
    "from keras import Sequential\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate= 0.001\n",
    "decay_speed = 1e-6\n",
    "momentum = 0.09 \n",
    "loss_function = \"sparse_categorical_crossentropy\"\n",
    "source_model = VGG19(weights=None)\n",
    "drop_layer = Dropout(0.5)\n",
    "drop_layer2 = Dropout(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "for layer in source_model.layers[:-1]:\n",
    "    if layer == source_model.layers[-25]:\n",
    "        model.add(BatchNormalization())\n",
    "    model.add(layer)\n",
    "model.add(Dense(num_classes, activation = \"Softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim1 = keras.optimizers.legacy.RMSprop(lr= learning_rate)\n",
    "model.compile(optimizer=optim1,\n",
    "            loss=loss_function,\n",
    "            metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_reshape(im, target_size):\n",
    "    return cv2.reshape(im, target_size)\n",
    "def get_batch(dataframe, start, batch_size):\n",
    "    image_array = []\n",
    "    label_array = []\n",
    "    end_img = start + batch_size\n",
    "    if (end_img) > len(dataframe):\n",
    "        end_img = len(dataframe)\n",
    "        \n",
    "        for idx in range(start, end_img):\n",
    "            n=idx\n",
    "        im, label = get_image_from_number(n, dataframe)\n",
    "        im = image_reshape(im, 224, 224)/ 255.0\n",
    "        image_array.append(im)\n",
    "        label_array.append(label)\n",
    "        \n",
    "        label_array = encode_label(label_array)\n",
    "        return np.array(image_array), np.array(label_array)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epoch_shuffle = True\n",
    "weight_classes = True\n",
    "epochs = 1\n",
    "\n",
    "train, val =np.split(df.sample(frac=1), [int(0.8*len(df))])\n",
    "print (len(train))\n",
    "print (len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e in range (epochs):\n",
    "    print(\"Epochs:\" + str(e+1) + \"/\" + str(epochs))\n",
    "    if epoch_shuffle:\n",
    "        train = train.sample(frac = 1)\n",
    "    for it in range(int(np.ceil(len(train)/batch_size))):\n",
    "        x_train, y_train = get_batch(train, it*batch_size, batch_size)\n",
    "        \n",
    "        model.train_on_batch(x_train, y_train)\n",
    "        \n",
    "model.save(\"Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "errors = 0\n",
    "good_preds = []\n",
    "bad_preds = []\n",
    "\n",
    "for it in range(int(np.ceil(len(val)/batch_size))):\n",
    "    x_val, y_val = get_batch(val, it*batch_size, batch_size)\n",
    "    \n",
    "    result = model.predit(x_val)\n",
    "    cla = np.argmax(result, axis = 1)\n",
    "    for idx, res in enumerate(result):\n",
    "        if cla[idx] != y_val[idx]:\n",
    "            errors = errors + 1\n",
    "            bad_preds.appened([batch_size*it + idx], cla[idx], res[cla[idx]])\n",
    "        else:\n",
    "            good_preds.append([batch_size*it + idx], cla[idx], res[cla[idx]])\n",
    "            \n",
    "for i in range(1,6):\n",
    "    n = int(good_preds[0])\n",
    "    img, lbl = get_image_from_number(n, val)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
